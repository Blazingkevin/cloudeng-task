
--- Start of gke/main.tf ---
resource "google_container_cluster" "primary" {
  name     = var.cluster_name
  location = var.region

  networking_mode          = "VPC_NATIVE"
  remove_default_node_pool = true

  ip_allocation_policy {}
  network    = var.vpc_self_link
  subnetwork = var.subnet_self_link

  initial_node_count = 1

  node_config {
    service_account = var.service_account_email
  }

  provisioner "local-exec" {
    command = "echo 'Waiting for GKE cluster to be ready...' && sleep 120"
  }
}

resource "google_container_node_pool" "primary_nodes" {
  name     = "${var.cluster_name}-node-pool"
  cluster  = google_container_cluster.primary.name
  location = google_container_cluster.primary.location

  autoscaling {
    min_node_count = 1
    max_node_count = 3
  }

  node_config {
    machine_type = "e2-medium"
    oauth_scopes = [
      "https://www.googleapis.com/auth/cloud-platform",
      "https://www.googleapis.com/auth/devstorage.read_only"
    ]
    service_account = var.service_account_email
  }

  provisioner "local-exec" {
    command = "echo 'Waiting for GKE cluster to be ready...' && sleep 120"
  }
}

resource "kubernetes_namespace" "default" {
  metadata {
    name = "default3"
  }

  depends_on = [
    google_container_node_pool.primary_nodes,
    google_container_cluster.primary
  ]

  provisioner "local-exec" {
    command = "echo 'Waiting for GKE cluster to be ready...' && sleep 120"
  }
}

resource "kubernetes_deployment" "api" {
  metadata {
    name      = "gke-terraform-api2"
    namespace = kubernetes_namespace.default.metadata[0].name
    # namespace = "default"
  }

  spec {
    replicas = 1

    selector {
      match_labels = {
        app = "gke-terraform-api2"
      }
    }

    template {
      metadata {
        labels = {
          app = "gke-terraform-api2"
        }
      }

      spec {
        container {
          name = "gke-terraform-api2"
          # image = "gcr.io/${var.project_id}/gke-terraform-api:v1.0.0"
          image = "us-central1-docker.pkg.dev/${var.project_id}/my-repo/gke-terraform-api:v1.0.0"
          port {
            container_port = 8080
          }
        }
      }
    }
  }

  provisioner "local-exec" {
    command = "echo 'Waiting for GKE cluster to be ready...' && sleep 120"
  }
}

resource "kubernetes_service" "api_service" {
  metadata {
    name      = "gke-terraform-api2-service"
    namespace = kubernetes_namespace.default.metadata[0].name
    # namespace = "default"
  }

  spec {
    selector = {
      app = "gke-terraform-api2"
    }

    port {
      port        = 80
      target_port = 8080
    }

    type = "LoadBalancer"
  }

  provisioner "local-exec" {
    command = "echo 'Waiting for GKE cluster to be ready...' && sleep 120"
  }
}

resource "kubernetes_ingress_v1" "api_ingress" {
  metadata {
    name      = "gke-terraform-api2-ingress"
    namespace = kubernetes_namespace.default.metadata[0].name
    # namespace = "default"
  }

  spec {
    default_backend {
      service {
        name = kubernetes_service.api_service.metadata[0].name
        port {
          number = 80
        }
      }
    }

    rule {
      http {
        path {
          path = "/"
          backend {
            service {
              name = kubernetes_service.api_service.metadata[0].name
              port {
                number = 80
              }
            }
          }
        }
      }
    }

    tls {
      secret_name = "tls-secret"
    }
  }

  provisioner "local-exec" {
    command = "echo 'Waiting for GKE cluster to be ready...' && sleep 120"
  }
}


--- End of gke/main.tf ---

--- Start of gke/outputs.tf ---
output "kubernetes_endpoint" {
  description = "The external IP of the API load balancer"
  value       = kubernetes_service.api_service.status[0].load_balancer[0].ingress[0].ip
}

output "cluster_endpoint" {
  description = "The endpoint of the GKE cluster"
  value       = google_container_cluster.primary.endpoint
}

output "cluster_ca_certificate" {
  description = "The base64-encoded public certificate for the cluster"
  value       = google_container_cluster.primary.master_auth[0].cluster_ca_certificate
}

--- End of gke/outputs.tf ---

--- Start of gke/variables.tf ---
variable "project_id" {
  description = "The project ID to deploy to"
  type        = string
}

variable "region" {
  description = "The region to deploy to"
  type        = string
  default     = "us-central1"
}

variable "cluster_name" {
  description = "The name of the GKE cluster"
  type        = string
}

variable "vpc_self_link" {
  description = "The self link of the VPC"
  type        = string
}

variable "subnet_self_link" {
  description = "The self link of the subnet"
  type        = string
}

variable "service_account_email" {
  description = "The email of the service account to use for the GKE cluster"
  type        = string
}

--- End of gke/variables.tf ---

--- Start of iam/main.tf ---
resource "google_service_account" "k8s_sa" {
  account_id   = "k8s-service-account2"
  display_name = "Kubernetes Service Account"

  provisioner "local-exec" {
    command = "echo 'Waiting for GKE cluster to be ready...' && sleep 120"
  }
}

resource "google_project_iam_binding" "gke_cluster_role" {
  project = var.project_id
  role    = "roles/container.clusterAdmin"

  members = [
    "serviceAccount:${google_service_account.k8s_sa.email}"
  ]

  provisioner "local-exec" {
    command = "echo 'Waiting for GKE cluster to be ready...' && sleep 120"
  }
}

resource "google_project_iam_binding" "gke_kubernetes_admin" {
  project = var.project_id
  role    = "roles/container.admin"

  members = [
    "serviceAccount:${google_service_account.k8s_sa.email}"
  ]

  provisioner "local-exec" {
    command = "echo 'Waiting for GKE cluster to be ready...' && sleep 120"
  }
}

resource "google_project_iam_binding" "gke_node_storage_access" {
  project = var.project_id
  role    = "roles/artifactregistry.reader"

  members = [
    "serviceAccount:${google_service_account.k8s_sa.email}"
  ]

  provisioner "local-exec" {
    command = "echo 'Waiting for GKE cluster to be ready...' && sleep 120"
  }
}

# resource "google_project_iam_binding" "deny_overprivileged_roles" {
#   project = var.project_id
#   role    = "roles/owner"

#   members = [
#     "serviceAccount:${google_service_account.k8s_sa.email}"
#   ]
# }

--- End of iam/main.tf ---

--- Start of iam/outputs.tf ---
output "iam_policy_status" {
  description = "Status of IAM policy enforcement"
  value       = "Policies applied"
}


output "k8s_service_account_email" {
  description = "The email of the Kubernetes service account"
  value       = google_service_account.k8s_sa.email
}

--- End of iam/outputs.tf ---

--- Start of iam/variables.tf ---
variable "project_id" {
  description = "The project ID to deploy to"
  type        = string
}

--- End of iam/variables.tf ---

--- Start of network/main.tf ---
resource "google_compute_network" "vpc_network" {
  name = var.vpc_name
}

resource "google_compute_subnetwork" "subnetwork" {
  name          = "${var.vpc_name}-subnet"
  ip_cidr_range = "10.0.0.0/16"
  network       = google_compute_network.vpc_network.name
  region        = var.region
}

resource "google_compute_router" "nat_router" {
  name    = "nat-router2"
  network = google_compute_network.vpc_network.name
  region  = var.region
}

resource "google_compute_router_nat" "nat_gw" {
  name                               = "nat-gw"
  router                             = google_compute_router.nat_router.name
  region                             = google_compute_router.nat_router.region
  nat_ip_allocate_option             = "AUTO_ONLY"
  source_subnetwork_ip_ranges_to_nat = "ALL_SUBNETWORKS_ALL_IP_RANGES"
}

resource "google_compute_firewall" "allow_internal" {
  name    = "allow-internal2"
  network = google_compute_network.vpc_network.name

  allow {
    protocol = "tcp"
    ports    = ["0-65535"]
  }

  source_ranges = ["10.0.0.0/16"]
  direction     = "INGRESS"
  target_tags   = ["internal"]
}

resource "google_compute_firewall" "allow_ssh" {
  name    = "allow-ssh2"
  network = google_compute_network.vpc_network.name

  allow {
    protocol = "tcp"
    ports    = ["22"]
  }

  source_ranges = ["0.0.0.0/0"]
  direction     = "INGRESS"
  target_tags   = ["ssh"]
}

resource "google_compute_firewall" "allow_health_checks" {
  name    = "allow-health-checks2"
  network = google_compute_network.vpc_network.name

  allow {
    protocol = "tcp"
    ports    = ["80", "443"]
  }

  source_ranges = ["130.211.0.0/22", "35.191.0.0/16"]
  direction     = "INGRESS"
  target_tags   = ["http-server", "https-server"]
}

resource "google_compute_firewall" "allow_egress" {
  name    = "allow-egress"
  network = google_compute_network.vpc_network.name

  allow {
    protocol = "tcp"
    ports    = ["80", "443"]
  }

  direction          = "EGRESS"
  destination_ranges = ["0.0.0.0/0"]
}


--- End of network/main.tf ---

--- Start of network/outputs.tf ---
output "vpc_self_link" {
  description = "The self link of the VPC"
  value       = google_compute_network.vpc_network.self_link
}

output "subnet_self_link" {
  description = "The self link of the subnet"
  value       = google_compute_subnetwork.subnetwork.self_link
}

--- End of network/outputs.tf ---

--- Start of network/variables.tf ---
variable "project_id" {
  description = "The project ID to deploy to"
  type        = string
}

variable "region" {
  description = "The region to deploy to"
  type        = string
  default     = "us-central1"
}

variable "vpc_name" {
  description = "The name of the VPC"
  type        = string
}

--- End of network/variables.tf ---
